import streamlit as st
from groq import Groq

# --- 1. Configura√ß√£o da P√°gina ---
st.set_page_config(page_title="Minha Assistente", page_icon="ü§ñ")
st.title("Assistente Pessoal (Llama 3.3)")

# --- 2. Conex√£o com a API ---
try:
    client = Groq(api_key=st.secrets["GROQ_API_KEY"])
except Exception as e:
    st.error("‚ö†Ô∏è Erro na Chave API. Verifique os Secrets.")
    st.stop()

MODEL_ID = "llama-3.3-70b-versatile"

# --- 3. Mem√≥ria Nova (Reset For√ßado) ---
# Mudamos o nome para 'memoria_v3' para ignorar qualquer lixo das tentativas anteriores
if "memoria_v3" not in st.session_state:
    st.session_state.memoria_v3 = []

# Bot√£o de emerg√™ncia na barra lateral
if st.sidebar.button("üóëÔ∏è Limpar Tudo"):
    st.session_state.memoria_v3 = []
    st.rerun()

# --- 4. Mostra o Hist√≥rico na Tela ---
for message in st.session_state.memoria_v3:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- 5. Processamento da Mensagem ---
if prompt := st.chat_input("Escreva aqui..."):
    
    # Salva e mostra a mensagem do usu√°rio
    st.session_state.memoria_v3.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Gera a resposta da IA
    with st.chat_message("assistant"):
        try:
            # --- O GRANDE SEGREDO (FILTRO DE SEGURAN√áA) ---
            # Criamos uma lista limpa apenas para enviar para a API (n√£o tocamos na mem√≥ria visual)
            messages_para_api = [
                {"role": "system", "content": "Voc√™ √© uma assistente √∫til e amig√°vel. Responda sempre em Portugu√™s do Brasil."}
            ]
            
            # S√≥ adicionamos mensagens que TEM CONTE√öDO REAL
            for m in st.session_state.memoria_v3:
                conteudo = str(m.get("content", "")) # Garante que √© string
                if len(conteudo.strip()) > 0:       # S√≥ aceita se n√£o for vazio
                    messages_para_api.append({"role": m["role"], "content": conteudo})

            # Chama a IA com a lista limpa
            stream = client.chat.completions.create(
                model=MODEL_ID,
                messages=messages_para_api,
                stream=True
            )
            
            # Escreve na tela
            response = st.write_stream(stream)
            
            # S√≥ salva no hist√≥rico se a resposta n√£o for vazia
            if response and len(str(response).strip()) > 0:
                st.session_state.memoria_v3.append({"role": "assistant", "content": response})
            else:
                # Se veio vazio, recarrega para n√£o travar
                st.rerun()

        except Exception as e:
            st.error(f"Erro de conex√£o: {e}")
            # Se deu erro, remove a √∫ltima pergunta para n√£o travar o fluxo
            if st.session_state.memoria_v3 and st.session_state.memoria_v3[-1]["role"] == "user":
                st.session_state.memoria_v3.pop()
