import streamlit as st
from groq import Groq
from tavily import TavilyClient
import edge_tts
import asyncio

# --- 1. Configura√ß√£o ---
st.set_page_config(page_title="Jarvis Pro", page_icon="üß†")
st.title("Assistente Aut√¥nomo (V2 Blindada)")

# --- 2. Conex√£o ---
try:
    client = Groq(api_key=st.secrets["GROQ_API_KEY"])
    tavily = TavilyClient(api_key=st.secrets["TAVILY_API_KEY"])
except Exception as e:
    st.error("‚ö†Ô∏è Erro nas Chaves API.")
    st.stop()

# Usaremos o modelo POTENTE para tudo agora, para evitar erros de julgamento
MODEL_ID = "llama-3.3-70b-versatile"

# --- 3. Mem√≥ria ---
if "memoria_v3" not in st.session_state:
    st.session_state.memoria_v3 = []
if "ultimo_audio" not in st.session_state:
    st.session_state.ultimo_audio = None

if st.sidebar.button("üóëÔ∏è Limpar Tudo"):
    st.session_state.memoria_v3 = []
    st.session_state.ultimo_audio = None
    st.rerun()

# --- FUN√á√ïES INTELIGENTES ---

def cerebro_decisor(pergunta):
    """
    Decide se busca ou n√£o. Agora com 3 camadas de seguran√ßa.
    """
    # 1. REDE DE SEGURAN√áA (Palavras-chave que OBRIGAM a busca)
    termos_obrigatorios = ["hoje", "agora", "cota√ß√£o", "pre√ßo", "valor", "not√≠cia", 
                          "clima", "tempo", "d√≥lar", "euro", "bitcoin", "jogo", "resultado", 
                          "lan√ßamento", "√∫ltimo", "atual", "quem ganhou"]
    
    if any(termo in pergunta.lower() for termo in termos_obrigatorios):
        return True # For√ßa a busca sem nem perguntar pra IA

    # 2. DECIS√ÉO DA IA (Com prompt refor√ßado)
    system_prompt = """
    Voc√™ √© um Supervisor de Busca. Sua √∫nica fun√ß√£o √© dizer 'BUSCAR' ou 'RESPONDER'.
    
    Regras R√çGIDAS:
    - Perguntas sobre fatos atuais, pre√ßos, eventos recentes, clima ou pessoas vivas -> DIGA 'BUSCAR'.
    - Perguntas te√≥ricas, ajuda com c√≥digo, tradu√ß√µes, poemas ou papo furado -> DIGA 'RESPONDER'.
    
    Exemplos:
    User: "Quanto t√° o d√≥lar?" -> Assistant: BUSCAR
    User: "Quem √© o presidente do Brasil?" -> Assistant: BUSCAR
    User: "Crie um poema." -> Assistant: RESPONDER
    User: "O que √© Python?" -> Assistant: RESPONDER
    """
    
    try:
        completion = client.chat.completions.create(
            model=MODEL_ID, # Usando o 70b para ser mais esperto
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": pergunta}
            ],
            temperature=0
        )
        decisao = completion.choices[0].message.content.strip().upper()
        return "BUSCAR" in decisao
    except:
        return False

def buscar_tavily(pergunta):
    try:
        # Aumentei para 'advanced' se quiser mais precis√£o, mas 'basic' √© mais r√°pido
        response = tavily.search(query=pergunta, search_depth="basic", max_results=3)
        contexto = []
        for r in response.get('results', []):
            contexto.append(f"- {r['title']}: {r['content']}")
        return "\n".join(contexto)
    except: return None

def ouvir_audio(audio_bytes):
    try:
        return client.audio.transcriptions.create(
            file=("temp.wav", audio_bytes, "audio/wav"),
            model="whisper-large-v3",
            response_format="text",
            language="pt"
        )
    except: return None

async def falar(texto):
    OUTPUT = "resposta.mp3"
    VOICE = "pt-BR-FranciscaNeural"
    await edge_tts.Communicate(texto, VOICE).save(OUTPUT)
    return OUTPUT

# --- 4. Interface ---
chat_container = st.container()
with chat_container:
    for m in st.session_state.memoria_v3:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

st.divider()
col1, col2 = st.columns([0.2, 0.8])

texto_input = None
falar_resposta = False

with col2:
    if txt := st.chat_input("Pergunte algo..."):
        texto_input = txt

with col1:
    if audio := st.audio_input("üéôÔ∏è"):
        if audio != st.session_state.ultimo_audio:
            st.session_state.ultimo_audio = audio
            with st.spinner("Ouvindo..."):
                if transcricao := ouvir_audio(audio):
                    texto_input = transcricao
                    falar_resposta = True

# --- 5. Fluxo Principal ---
if texto_input:
    st.session_state.memoria_v3.append({"role": "user", "content": texto_input})
    with chat_container.chat_message("user"):
        st.markdown(texto_input)

    with chat_container.chat_message("assistant"):
        placeholder = st.empty()
        dados_web = ""
        
        # DECIS√ÉO
        with st.status("üß† Pensando...", expanded=True) as status:
            precisa_busca = cerebro_decisor(texto_input)
            
            if precisa_busca:
                status.write("üåç Buscando informa√ß√µes atualizadas...")
                raw_data = buscar_tavily(texto_input)
                if raw_data:
                    dados_web = f"\n\n[DADOS DA INTERNET]:\n{raw_data}\n"
                    status.update(label="‚úÖ Encontrei dados na rede!", state="complete", expanded=False)
                else:
                    status.update(label="‚ùå Erro na busca (tentando sem dados)", state="error", expanded=False)
            else:
                status.update(label="üìö Usando conhecimento interno", state="complete", expanded=False)

        # RESPOSTA
        try:
            with st.spinner("Formulando resposta..."):
                msgs = [{"role": "system", "content": "Voc√™ √© uma assistente prestativa. Use os dados da web se fornecidos. Responda em Portugu√™s."}]
                for m in st.session_state.memoria_v3[:-1]:
                    if m.get("content"): msgs.append({"role": m["role"], "content": str(m["content"])})
                
                msgs.append({"role": "user", "content": texto_input + dados_web})

                stream = client.chat.completions.create(model=MODEL_ID, messages=msgs, stream=False)
                resp = stream.choices[0].message.content
                placeholder.markdown(resp)
                
                if falar_resposta:
                    with st.spinner("Gerando √°udio..."):
                        audio_file = asyncio.run(falar(resp))
                        st.audio(audio_file, format="audio/mp3", autoplay=True)
                
                st.session_state.memoria_v3.append({"role": "assistant", "content": resp})
        
        except Exception as e:
            st.error(f"Erro: {e}")
