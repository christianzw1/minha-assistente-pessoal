import streamlit as st
from groq import Groq
import edge_tts
import asyncio
import os

# --- 1. Configura√ß√£o ---
st.set_page_config(page_title="Jarvis Neural", page_icon="üéôÔ∏è")
st.title("Assistente Pessoal (Voz Neural)")

# --- 2. Conex√£o ---
try:
    client = Groq(api_key=st.secrets["GROQ_API_KEY"])
except Exception as e:
    st.error("‚ö†Ô∏è Erro na Chave API.")
    st.stop()

MODEL_ID = "llama-3.3-70b-versatile"

# --- 3. Mem√≥ria Blindada ---
if "memoria_v3" not in st.session_state:
    st.session_state.memoria_v3 = []

# Bot√£o de limpeza discreto na sidebar
if st.sidebar.button("üóëÔ∏è Limpar Mem√≥ria"):
    st.session_state.memoria_v3 = []
    st.rerun()

# --- FUN√á√ïES DE √ÅUDIO ---

def ouvir_audio_whisper(audio_bytes):
    """Ouvidos: Transcreve o √°udio usando Groq Whisper (R√°pido)"""
    try:
        return client.audio.transcriptions.create(
            file=("temp.wav", audio_bytes, "audio/wav"),
            model="whisper-large-v3",
            response_format="text",
            language="pt"
        )
    except Exception as e:
        st.error(f"Erro ao ouvir: {e}")
        return None

async def gerar_audio_neural(texto):
    """Boca: Gera √°udio neural usando Edge-TTS (Microsoft Azure Free)"""
    OUTPUT_FILE = "resposta_neural.mp3"
    # Vozes PT-BR dispon√≠veis: 'pt-BR-FranciscaNeural' (Mulher) ou 'pt-BR-AntonioNeural' (Homem)
    VOICE = "pt-BR-FranciscaNeural" 
    
    communicate = edge_tts.Communicate(texto, VOICE)
    await communicate.save(OUTPUT_FILE)
    return OUTPUT_FILE

# --- 4. Interface de Chat ---
# Container para o hist√≥rico (deixa espa√ßo para os inputs embaixo)
chat_container = st.container()

with chat_container:
    for message in st.session_state.memoria_v3:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# --- 5. √Årea de Input (H√≠brida) ---
# Usamos um container fixo ou a parte inferior para organizar
st.divider() # Linha separadora
col_audio, col_texto = st.columns([0.2, 0.8]) # Layout lado a lado (aprox)

prompt_final = None
usou_audio = False

# Input de √Åudio (Novo Widget Compacto)
with col_audio:
    audio_gravado = st.audio_input("üéôÔ∏è") # √çcone minimalista

# Input de Texto
with col_texto:
    prompt_texto = st.chat_input("Digite ou grave ao lado...")

# L√≥gica de Prioridade (Quem mandar primeiro, ganha)
if audio_gravado:
    with st.spinner("Processando voz..."):
        prompt_final = ouvir_audio_whisper(audio_gravado)
        usou_audio = True
elif prompt_texto:
    prompt_final = prompt_texto

# --- 6. Processamento Inteligente ---
if prompt_final:
    # Mostra mensagem do usu√°rio (se for texto, o chat input j√° mostra, se for √°udio for√ßamos)
    if usou_audio:
        with chat_container.chat_message("user"):
            st.markdown(prompt_final)
    
    st.session_state.memoria_v3.append({"role": "user", "content": prompt_final})

    # Resposta da IA
    with chat_container.chat_message("assistant"):
        placeholder_texto = st.empty()
        placeholder_audio = st.empty()
        
        try:
            # 1. Filtro de Seguran√ßa
            msgs_api = [{"role": "system", "content": "Voc√™ √© uma assistente √∫til, carism√°tica e direta. Responda em Portugu√™s."}]
            for m in st.session_state.memoria_v3:
                if m.get("content"):
                    msgs_api.append({"role": m["role"], "content": str(m["content"])})

            # 2. Gera Texto (Llama 3)
            with st.spinner("Pensando..."):
                completion = client.chat.completions.create(
                    model=MODEL_ID,
                    messages=msgs_api,
                    stream=False
                )
                resposta_texto = completion.choices[0].message.content
                placeholder_texto.markdown(resposta_texto)

            # 3. Gera √Åudio Neural (Se o usu√°rio falou por voz)
            if usou_audio:
                with st.spinner("Gerando voz natural..."):
                    # Roda o Edge-TTS (Ass√≠ncrono)
                    arquivo_audio = asyncio.run(gerar_audio_neural(resposta_texto))
                    
                    # Toca o √°udio automaticamente
                    if arquivo_audio:
                        placeholder_audio.audio(arquivo_audio, format="audio/mp3", autoplay=True)

            # 4. Salva Mem√≥ria
            st.session_state.memoria_v3.append({"role": "assistant", "content": resposta_texto})

        except Exception as e:
            st.error(f"Ocorreu um erro: {e}")
