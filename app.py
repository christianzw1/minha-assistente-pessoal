import streamlit as st
from groq import Groq
from gtts import gTTS
import os

# --- 1. Configura√ß√£o ---
st.set_page_config(page_title="Jarvis Pessoal", page_icon="üéôÔ∏è")
st.title("Assistente Pessoal (Modo Voz)")

# --- 2. Conex√£o ---
try:
    client = Groq(api_key=st.secrets["GROQ_API_KEY"])
except Exception as e:
    st.error("‚ö†Ô∏è Erro na Chave API.")
    st.stop()

MODEL_ID = "llama-3.3-70b-versatile"

# --- 3. Gerenciamento de Mem√≥ria (Blindado) ---
if "memoria_v3" not in st.session_state:
    st.session_state.memoria_v3 = []

# Bot√£o para limpar
if st.sidebar.button("üóëÔ∏è Nova Conversa"):
    st.session_state.memoria_v3 = []
    st.rerun()

# --- FUN√á√ïES DE VOZ ---

def ouvir_audio(audio_bytes):
    """Usa o Whisper da Groq para transcrever √°udio em texto"""
    try:
        transcription = client.audio.transcriptions.create(
            file=("temp.wav", audio_bytes, "audio/wav"),
            model="whisper-large-v3", # Modelo de ouvido da Groq
            response_format="text",
            language="pt"
        )
        return transcription
    except Exception as e:
        st.error(f"Erro ao ouvir: {e}")
        return None

def falar_texto(texto):
    """Transforma texto em √°udio usando Google TTS"""
    try:
        tts = gTTS(text=texto, lang='pt', slow=False)
        filename = "resposta_audio.mp3"
        tts.save(filename)
        return filename
    except Exception as e:
        st.warning(f"N√£o consegui gerar o √°udio: {e}")
        return None

# --- 4. Interface ---

# Mostra o hist√≥rico visual
for message in st.session_state.memoria_v3:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- 5. Entradas (Voz ou Texto) ---
col1, col2 = st.columns([0.8, 0.2])

# Vari√°vel para guardar o prompt final
prompt_usuario = None
usou_audio = False

# A. Entrada de √Åudio (Novo!)
audio_gravado = st.audio_input("üéôÔ∏è Clique para gravar")

if audio_gravado:
    with st.spinner("Ouvindo..."):
        texto_transcrito = ouvir_audio(audio_gravado)
        if texto_transcrito:
            prompt_usuario = texto_transcrito
            usou_audio = True

# B. Entrada de Texto (Backup)
prompt_texto = st.chat_input("Ou digite aqui...")
if prompt_texto:
    prompt_usuario = prompt_texto

# --- 6. Processamento ---
if prompt_usuario:
    # Mostra mensagem do usu√°rio
    if not usou_audio: # Se for √°udio, o player j√° aparece, n√£o duplicamos texto
        with st.chat_message("user"):
            st.markdown(prompt_usuario)
    
    st.session_state.memoria_v3.append({"role": "user", "content": prompt_usuario})

    # Gera resposta da IA
    with st.chat_message("assistant"):
        with st.spinner("Pensando..."):
            try:
                # Prepara hist√≥rico limpo
                messages_api = [{"role": "system", "content": "Voc√™ √© uma assistente √∫til. Responda de forma direta e amig√°vel em Portugu√™s."}]
                for m in st.session_state.memoria_v3:
                    if m.get("content"):
                        messages_api.append({"role": m["role"], "content": str(m["content"])})

                # Chama Llama 3
                completion = client.chat.completions.create(
                    model=MODEL_ID,
                    messages=messages_api,
                    stream=False
                )
                
                resposta = completion.choices[0].message.content
                st.markdown(resposta)
                
                # Gera o √Åudio da resposta
                if usou_audio: # S√≥ fala se o usu√°rio falou com ela (para n√£o ser chato no chat de texto)
                    arquivo_audio = falar_texto(resposta)
                    if arquivo_audio:
                        st.audio(arquivo_audio, format="audio/mp3", autoplay=True)

                # Salva na mem√≥ria
                st.session_state.memoria_v3.append({"role": "assistant", "content": resposta})

            except Exception as e:
                st.error(f"Erro: {e}")
